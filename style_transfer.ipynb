{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sungreong/All-About-the-GAN/blob/master/style_transfer.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "hy31D7gzprN1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Colab 에서 Style Transfer 해보기 \n",
        "\n",
        "## [Original Code](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/neural_style_transfer)"
      ]
    },
    {
      "metadata": {
        "id": "O29Jh3WxVzmc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## CUDA 8\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8N5A7deilV1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-98tgd5nXUE7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "57L4zeoJXXiK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.version\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nm0uFlEeX2Zi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!cat /etc/issue.net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lz81zNSFYMwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NMT1ktXnYPYJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_N2_RRepYTBI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!df -h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "65Ns0BAIYVKZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aXab3QgUYcAx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Google Drive 와 연동하기\n",
        "\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d-rhbmqwYx4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-bYU08LYyIv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd drive/Colab\\ Notebooks/Pytorch/style\\ transfer/ ; ls -al"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwX618WiYyLX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/Colab Notebooks/Pytorch/style transfer\")\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GwPxJMDtb3hK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -al"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMktyBITka2i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_lYpG4SIw7Sq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    ## 변경 가능한 부분 \n",
        "\n",
        "```\n",
        "    parser.add_argument('--content', type=str, default='content.png')\n",
        "    parser.add_argument('--style', type=str, default='style.png')\n",
        "    parser.add_argument('--max_size', type=int, default=400)\n",
        "    parser.add_argument('--total_step', type=int, default=2000)\n",
        "    parser.add_argument('--log_step', type=int, default=10)\n",
        "    parser.add_argument('--sample_step', type=int, default=500)\n",
        "    parser.add_argument('--style_weight', type=float, default=100)\n",
        "    parser.add_argument('--lr', type=float, default=0.003)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "AXE-0JkfYyN2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## 원래 이렇게 하면 되야하는데 돌아가야하는데 안돌아감 => 잘돌아감\n",
        "!python3 main.py --content='content3.jpg' --style='style9.jpg' --total_step=5000  --style_weight=3000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OZNW9ckH2Q7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main.py --content='content2.jpg' --style='style4.jpg' --total_step=4000 --style_weight=5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YhToax6Davh8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## main.py 있는 값을 빼와서 해보기 \n",
        "from __future__ import division\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KnE7zn-CbMfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def load_image(image_path, transform=None, max_size=None, shape=None):\n",
        "    \"\"\"Load an image and convert it to a torch tensor.\"\"\"\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    if max_size:\n",
        "        scale = max_size / max(image.size)\n",
        "        size = np.array(image.size) * scale\n",
        "        image = image.resize(size.astype(int), Image.ANTIALIAS)\n",
        "    \n",
        "    if shape:\n",
        "        image = image.resize(shape, Image.LANCZOS)\n",
        "    \n",
        "    if transform:\n",
        "        image = transform(image).unsqueeze(0)\n",
        "    \n",
        "    return image.to(device)\n",
        "\n",
        "\n",
        "class VGGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"Select conv1_1 ~ conv5_1 activation maps.\"\"\"\n",
        "        super(VGGNet, self).__init__()\n",
        "        self.select = ['0', '5', '10', '19', '28'] \n",
        "        self.vgg = models.vgg19(pretrained=True).features\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"Extract multiple convolutional feature maps.\"\"\"\n",
        "        features = []\n",
        "        for name, layer in self.vgg._modules.items():\n",
        "            x = layer(x)\n",
        "            if name in self.select:\n",
        "                features.append(x)\n",
        "        return features\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "utikdD-EbKgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main( content_filename , style_filename ):\n",
        "    \n",
        "    # Image preprocessing\n",
        "    # VGGNet was trained on ImageNet where images are normalized by mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].\n",
        "    # We use the same normalization statistics here.\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406), \n",
        "                             std=(0.229, 0.224, 0.225))])\n",
        "    \n",
        "    # Load content and style images\n",
        "    # Make the style image same size as the content image\n",
        "    content = load_image(content_filename , transform, max_size= 400 )\n",
        "    style = load_image(style_filename , transform, shape=[content.size(2), content.size(3)])\n",
        "    \n",
        "    # Initialize a target image with the content image\n",
        "    target = content.clone().requires_grad_(True)\n",
        "    \n",
        "    optimizer = torch.optim.Adam([target], lr=0.003, betas=[0.5, 0.999])\n",
        "    vgg = VGGNet().to(device).eval()\n",
        "    \n",
        "    for step in range(2000):\n",
        "        \n",
        "        # Extract multiple(5) conv feature vectors\n",
        "        target_features = vgg(target)\n",
        "        content_features = vgg(content)\n",
        "        style_features = vgg(style)\n",
        "\n",
        "        style_loss = 0\n",
        "        content_loss = 0\n",
        "        for f1, f2, f3 in zip(target_features, content_features, style_features):\n",
        "            # Compute content loss with target and content images\n",
        "            content_loss += torch.mean((f1 - f2)**2)\n",
        "\n",
        "            # Reshape convolutional feature maps\n",
        "            _, c, h, w = f1.size()\n",
        "            f1 = f1.view(c, h * w)\n",
        "            f3 = f3.view(c, h * w)\n",
        "\n",
        "            # Compute gram matrix\n",
        "            f1 = torch.mm(f1, f1.t())\n",
        "            f3 = torch.mm(f3, f3.t())\n",
        "\n",
        "            # Compute style loss with target and style images\n",
        "            style_loss += torch.mean((f1 - f3)**2) / (c * h * w) \n",
        "        \n",
        "        # Compute total loss, backprop and optimize\n",
        "        loss = content_loss + 100  * style_loss \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (step+1) % 10 == 0:\n",
        "            print ('Step [{}/{}], Content Loss: {:.4f}, Style Loss: {:.4f}' \n",
        "                   .format(step+1, 2000 , content_loss.item(), style_loss.item()))\n",
        "\n",
        "        if (step+1) % 500 == 0:\n",
        "            # Save the generated image\n",
        "            denorm = transforms.Normalize((-2.12, -2.04, -1.80), (4.37, 4.46, 4.44))\n",
        "            img = target.clone().squeeze()\n",
        "            img = denorm(img).clamp_(0, 1)\n",
        "            torchvision.utils.save_image(img, 'output-{}.png'.format(step+1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kH0uDyYfcPmi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main(content_filename = \"content.jpg\" , style_filename  =  \"style.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "izm9jGy0f9Mj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -al"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K-NSC5zKk88z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}